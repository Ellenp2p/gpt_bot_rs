use dotenv::dotenv;
use std::env;
use std::error::Error; 
use teloxide::{prelude::*, net::Download, types::File as TgFile, utils::command::BotCommands};
use reqwest::multipart::{Form, Part};
use serde::Deserialize;
use serde_json::Value;

// å¼•å…¥æ¨¡å—
mod db;
mod models;

// OpenAIå“åº”ç»“æ„
#[derive(Deserialize, Debug)]
struct OpenAIResponse {
    text: String,
}

// å®šä¹‰å‘½ä»¤
#[derive(BotCommands, Clone, Debug)]
#[command(
    rename_rule = "lowercase",
    description = "æ”¯æŒçš„å‘½ä»¤ï¼š",
    parse_with = "split"
)]
enum Command {
    #[command(description = "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")]
    Help,
    #[command(description = "å¼€å§‹ä½¿ç”¨æœºå™¨äºº")]
    Start,
    #[command(description = "æµ‹è¯•æœºå™¨äººæ˜¯å¦åœ¨çº¿")]
    Ping,
    #[command(description = "æ¸…é™¤èŠå¤©å†å²è®°å½•")]
    Clear,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error + Send + Sync>> {
    // åŠ è½½ç¯å¢ƒå˜é‡
    dotenv().ok();
    
    // è·å–ç¯å¢ƒå˜é‡
    let tg_token = env::var("TELEGRAM_BOT_TOKEN").expect("TELEGRAM_BOT_TOKEN not found");
    let openai_token = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY not found");
    
    // åˆå§‹åŒ–æ—¥å¿—
    pretty_env_logger::init();
    log::info!("Starting telegram bot...");
    
    // åˆå§‹åŒ–æ•°æ®åº“
    let db_pool = db::init_db().await?;
    log::info!("Database initialized successfully");
    
    // åˆ›å»ºæœºå™¨äºº
    let bot = Bot::new(tg_token);
    let db_pool_clone = db_pool.clone();
    let openai_token_clone = openai_token.clone();
    
    // æ›´æ–°å¤„ç†å™¨ï¼Œæ ¹æ®æ¶ˆæ¯ç±»å‹åˆ†æµ
    let message_handler = Update::filter_message()
        .branch(
            dptree::filter(|msg: Message| msg.voice().is_some())
                .endpoint(move |bot: Bot, msg: Message| {
                    let openai_token = openai_token_clone.clone();
                    let db = db_pool_clone.clone();
                    async move {
                        if let Err(err) = handle_voice_message(bot.clone(), msg.clone(), &openai_token, &db).await {
                            log::error!("è¯­éŸ³å¤„ç†é”™è¯¯: {:?}", err);
                            let _ = bot.send_message(msg.chat.id, "å¤„ç†è¯­éŸ³æ—¶å‘ç”Ÿé”™è¯¯").await;
                        }
                        respond(())
                    }
                }),
        )
        .branch(
            dptree::entry()
                .filter_command::<Command>()
                .endpoint({
                    let db = db_pool.clone();
                    let openai_token = openai_token.clone();
                    move |bot: Bot, msg: Message, cmd: Command| {
                        let db = db.clone();
                        let openai_token = openai_token.clone();
                        async move {
                            handle_command(bot, msg, cmd, &db, &openai_token).await
                        }
                    }
                }),
        )
        .branch(
            dptree::filter(|msg: Message| msg.text().is_some())
                .endpoint({
                    let db = db_pool.clone();
                    let openai_token = openai_token.clone();
                    move |bot: Bot, msg: Message| {
                        let db = db.clone();
                        let openai_token = openai_token.clone();
                        async move {
                            handle_text_message(bot, msg, &db, &openai_token).await
                        }
                    }
                }),
        );
    
    Dispatcher::builder(bot, message_handler)
        .default_handler(|upd| async move {
            log::warn!("æœªå¤„ç†çš„æ›´æ–°: {:?}", upd);
        })
        .error_handler(LoggingErrorHandler::with_custom_text(
            "å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯",
        ))
        .enable_ctrlc_handler()
        .build()
        .dispatch()
        .await;
    
    Ok(())
}

async fn handle_command(
    bot: Bot, 
    msg: Message, 
    cmd: Command, 
    db_pool: &db::DatabasePool, 
    openai_token: &str
) -> ResponseResult<()> {
    match cmd {
        Command::Help => {
            bot.send_message(
                msg.chat.id,
                Command::descriptions().to_string(),
            )
            .await?;
        }
        Command::Start => {
            bot.send_message(
                msg.chat.id,
                "ğŸ‘‹ æ¬¢è¿ä½¿ç”¨AIèŠå¤©æœºå™¨äºº!\n\nä½ å¯ä»¥ç›´æ¥å‘é€æ–‡å­—ä¸æˆ‘å¯¹è¯ï¼Œæˆ–å‘é€è¯­éŸ³æ¶ˆæ¯è®©æˆ‘è½¬å½•ã€‚\nä½¿ç”¨ /help æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤ã€‚",
            )
            .await?;
        }
        Command::Ping => {
            bot.send_message(msg.chat.id, "æˆ‘åœ¨çº¿ï¼").await?;
        }
        Command::Clear => {
            match models::Session::clear_history_by_chat_id(db_pool, msg.chat.id.0).await {
                Ok(_) => {
                    bot.send_message(msg.chat.id, "å·²æ¸…é™¤èŠå¤©å†å²è®°å½•ï¼").await?;
                },
                Err(e) => {
                    log::error!("æ¸…é™¤å†å²è®°å½•é”™è¯¯: {:?}", e);
                    bot.send_message(msg.chat.id, "æ¸…é™¤èŠå¤©å†å²æ—¶å‘ç”Ÿé”™è¯¯").await?;
                }
            }
        }
    };

    Ok(())
}

async fn handle_text_message(
    bot: Bot, 
    msg: Message, 
    db_pool: &db::DatabasePool, 
    openai_token: &str
) -> ResponseResult<()> {
    // å¤„ç†æ™®é€šæ–‡æœ¬æ¶ˆæ¯
    if let Some(text) = msg.text() {
        if !text.starts_with('/') { // ä¸æ˜¯å‘½ä»¤çš„æ™®é€šæ–‡æœ¬
            // æ˜¾ç¤º"æ­£åœ¨æ€è€ƒ"çš„æç¤º
            let chat_id = msg.chat.id;
            let thinking_message = bot.send_message(chat_id, "ğŸ¤” æ€è€ƒä¸­...").await?;
            
            // å¤„ç†æ¶ˆæ¯å¹¶è·å–å›å¤
            match process_chat_message(db_pool, chat_id.0, text, openai_token).await {
                Ok(response) => {
                    // åˆ é™¤"æ€è€ƒä¸­"çš„æ¶ˆæ¯
                    bot.delete_message(chat_id, thinking_message.id).await?;
                    
                    // å‘é€AIå›å¤
                    bot.send_message(chat_id, response).await?;
                },
                Err(e) => {
                    log::error!("GPTå¤„ç†é”™è¯¯: {:?}", e);
                    bot.edit_message_text(chat_id, thinking_message.id, "å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚").await?;
                }
            }
        }
    }
    Ok(())
}

async fn process_chat_message(
    db_pool: &db::DatabasePool, 
    chat_id: i64, 
    message: &str, 
    api_key: &str
) -> Result<String, Box<dyn Error + Send + Sync>> {
    // æŸ¥æ‰¾æˆ–åˆ›å»ºä¼šè¯
    let session_id = models::Session::find_or_create_by_chat_id(db_pool, chat_id).await?;
    
    // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    models::Message::create(db_pool, session_id, "user", message).await?;
    
    // è·å–å†å²æ¶ˆæ¯
    let history = models::Message::get_recent_messages(db_pool, session_id, 10).await?;
    
    // æ„å»º GPT è¯·æ±‚
    let messages: Vec<serde_json::Value> = history.iter().map(|msg| {
        serde_json::json!({
            "role": msg.role,
            "content": msg.content
        })
    }).collect();
    
    // æ·»åŠ å½“å‰æ¶ˆæ¯
    let mut all_messages = messages;
    
    // è°ƒç”¨ GPT API
    let client = reqwest::Client::builder().build()?;
    let response = client
        .post("https://api.openai.com/v1/chat/completions")
        .bearer_auth(api_key)
        .json(&serde_json::json!({
            "model": "gpt-3.5-turbo",
            "messages": all_messages,
            "temperature": 0.7
        }))
        .send()
        .await?;
    
    // å¤„ç† GPT å“åº”
    if response.status().is_success() {
        let json: Value = response.json().await?;
        if let Some(content) = json["choices"][0]["message"]["content"].as_str() {
            // ä¿å­˜ AI å›å¤
            models::Message::create(db_pool, session_id, "assistant", content).await?;
            Ok(content.to_string())
        } else {
            Err("æ— æ³•è§£æ GPT å“åº”".into())
        }
    } else {
        let error_text = response.text().await?;
        Err(format!("GPT API é”™è¯¯: {}", error_text).into())
    }
}

async fn handle_voice_message(bot: Bot, msg: Message, openai_token: &str, db_pool: &db::DatabasePool) -> Result<(), Box<dyn Error + Send + Sync>> {
    if let Some(voice) = msg.voice() {
        let chat_id = msg.chat.id;
        
        // å‘é€"å¤„ç†ä¸­"ä¿¡æ¯
        let processing_msg = bot.send_message(chat_id, "æ­£åœ¨å¤„ç†æ‚¨çš„è¯­éŸ³æ¶ˆæ¯ï¼Œè¯·ç¨å€™...").await?;
        
        // è·å–è¯­éŸ³æ–‡ä»¶
        let file_id = &voice.file.id;
        let file = bot.get_file(file_id).await?;
        
        // ä¸‹è½½è¯­éŸ³æ–‡ä»¶åˆ°å†…å­˜
        let voice_data = download_voice(&bot, &file).await?;
        
        // å‘é€åˆ°OpenAIè¿›è¡Œè½¬å½•
        match transcribe_audio(&voice_data, openai_token).await {
            Ok(text) => {
                // æ˜¾ç¤ºè½¬å½•ç»“æœ
                bot.edit_message_text(chat_id, processing_msg.id, format!("è¯­éŸ³å†…å®¹: {}", text)).await?;
                
                // å°†è½¬å½•å†…å®¹ä¿å­˜åˆ°æ•°æ®åº“
                let session_id = models::Session::find_or_create_by_chat_id(db_pool, chat_id.0).await?;
                models::Message::create(db_pool, session_id, "user", &text).await?;
                
                // æ˜¾ç¤º"æ­£åœ¨æ€è€ƒ"çš„æç¤º
                let thinking_message = bot.send_message(chat_id, "ğŸ¤” æ€è€ƒä¸­...").await?;
                
                // å¤„ç†æ¶ˆæ¯å¹¶è·å–å›å¤
                match process_chat_message(db_pool, chat_id.0, &text, openai_token).await {
                    Ok(response) => {
                        // åˆ é™¤"æ€è€ƒä¸­"çš„æ¶ˆæ¯
                        bot.delete_message(chat_id, thinking_message.id).await?;
                        
                        // å‘é€AIå›å¤
                        bot.send_message(chat_id, response).await?;
                    },
                    Err(e) => {
                        log::error!("GPTå¤„ç†é”™è¯¯: {:?}", e);
                        bot.edit_message_text(chat_id, thinking_message.id, "å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚").await?;
                    }
                }
            },
            Err(e) => {
                bot.edit_message_text(chat_id, processing_msg.id, format!("å¤„ç†è¯­éŸ³æ—¶å‡ºé”™: {}", e)).await?;
            }
        }
    }
    
    Ok(())
}

/// å°†æ–‡ä»¶ä¸‹è½½åˆ°å†…å­˜è€Œä¸æ˜¯ä¿å­˜ä¸ºæ–‡ä»¶
async fn download_voice(bot: &Bot, file: &TgFile) -> Result<Vec<u8>, Box<dyn Error + Send + Sync>> {
    // åˆ›å»ºå†…å­˜ç¼“å†²åŒº
    let mut buffer = Vec::new();
    
    // ä¸‹è½½æ–‡ä»¶åˆ°å†…å­˜
    bot.download_file(&file.path, &mut buffer).await?;
    
    Ok(buffer)
}

/// ä»å†…å­˜æ•°æ®ä¸­è½¬å½•éŸ³é¢‘
async fn transcribe_audio(audio_data: &[u8], api_key: &str) -> Result<String, Box<dyn Error + Send + Sync>> {
    // åˆ›å»ºmultipartè¡¨å•
    let part = Part::bytes(audio_data.to_vec())
        .file_name("audio.oga")
        .mime_str("audio/ogg")?;
    
    let form = Form::new()
        .part("file", part)
        .text("model", "whisper-1");
    
    // å‘é€è¯·æ±‚åˆ°OpenAI
    let client = reqwest::Client::new();
    let response = client
        .post("https://api.openai.com/v1/audio/transcriptions")
        .bearer_auth(api_key)
        .multipart(form)
        .send()
        .await?;
    
    // å¤„ç†å“åº”
    if response.status().is_success() {
        let json: Value = response.json().await?;
        if let Some(text) = json["text"].as_str() {
            Ok(text.to_string())
        } else {
            Err("æ— æ³•è·å–æ–‡å­—å†…å®¹".into())
        }
    } else {
        let error_text = response.text().await?;
        Err(format!("APIé”™è¯¯: {}", error_text).into())
    }
}
